{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26e001a-d9ad-4a85-80b9-03140f4cb361",
   "metadata": {},
   "source": [
    "# Sparse reproduction of clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a6196b-93ab-4ce7-b2c7-04f7bf073945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "from datetime import datetime, timedelta\n",
    "from random import sample, choice\n",
    "from statistics import mean, median_low\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from fog.tokenizers import WordTokenizer\n",
    "from fog.metrics import sparse_normalize, sparse_dot_product\n",
    "from fog.evaluation import best_matching\n",
    "from twitwi.constants import TWEET_DATETIME_FORMAT\n",
    "from stop_words import STOP_WORDS_FR\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b489f2-a483-4f77-8229-acb2c655707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e001aa35-3247-4bfa-82d5-1e8b4c990453",
   "metadata": {},
   "source": [
    "## Constants and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59114cb3-07ff-48b8-a4c0-7dfb149bb82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_DAY = timedelta(days=1)\n",
    "\n",
    "def parse_date(created_at):\n",
    "    return datetime.strptime(created_at, TWEET_DATETIME_FORMAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f7ace-67f1-4afb-b02a-e4efc518be28",
   "metadata": {},
   "source": [
    "## Reading tweets file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f768c4a4-8606-4b78-bf93-e0188735408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/event2018.tsv') as f:\n",
    "    ALL_TWEETS = list(csv.DictReader(f, delimiter='\\t'))\n",
    "    \n",
    "# Keeping tweets only once (to avoid fuzzy clusters present in the data)\n",
    "already_seen = set()\n",
    "TWEETS = []\n",
    "\n",
    "for tweet in ALL_TWEETS:\n",
    "    if tweet['id'] in already_seen:\n",
    "        continue\n",
    "    \n",
    "    already_seen.add(tweet['id'])\n",
    "    TWEETS.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263b7713-87a3-466a-9688-fa23ed49e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dates & parsing stuff\n",
    "for tweet in TWEETS:\n",
    "    tweet['event'] = int(tweet['event'])\n",
    "    tweet['date'] = parse_date(tweet['created_at'])\n",
    "    tweet['timestamp'] = tweet['date'].timestamp()\n",
    "    tweet['label'] = int(tweet['label'].split('.')[0]) if tweet['label'] else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984618b6-5c24-477a-9ed3-7a7aeed713a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making suuuuuuuure the tweets are sorted by date\n",
    "TWEETS = sorted(TWEETS, key=itemgetter('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce41a24-5cbf-4833-91ca-c2ff9b994463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 1018722125941755905\n",
      "label_day 0.0\n",
      "event 20180716001\n",
      "text #Rennes - La sortie de prison de Djamel Beghal [Vid√©o exclusive] via @letelegramme https://t.co/tbOthY1Ren\n",
      "text+quote+reply #Rennes - La sortie de prison de Djamel Beghal [Vid√©o exclusive] via @letelegramme https://t.co/tbOthY1Ren  \n",
      "image \n",
      "url_image \n",
      "user1 True\n",
      "user2 True\n",
      "user3 True\n",
      "created_at Mon Jul 16 05:00:56 +0000 2018\n",
      "label 0\n",
      "date 2018-07-16 05:00:56\n",
      "timestamp 1531710056.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in TWEETS[0].items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cfeef6e-7d15-41b6-ac37-53dafdf13ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 137757\n",
      "Total number of events: 327\n",
      "Total number of labels: 257\n",
      "Total number of tweets not labeled 41961\n"
     ]
    }
   ],
   "source": [
    "print('Total number of tweets:', len(TWEETS))\n",
    "print('Total number of events:', len(set(t['event'] for t in TWEETS)))\n",
    "print('Total number of labels:', len(set(t['label'] for t in TWEETS if t['label'] is not None)))\n",
    "print('Total number of tweets not labeled', sum(1 if t['label'] is None else 0 for t in TWEETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357cfbfa-1562-46e8-ac54-5f659a88ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUTH = defaultdict(list)\n",
    "\n",
    "for tweet in TWEETS:\n",
    "    if tweet['label'] is None:\n",
    "        continue\n",
    "        \n",
    "    TRUTH[tweet['label']].append(tweet['id'])\n",
    "\n",
    "TRUTH = list(TRUTH.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9ae949-8030-4c2d-b5b0-63db36f45205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_stats(clusters):\n",
    "    lens = [len(cluster) for cluster in clusters]\n",
    "    \n",
    "    print('Number of clusters:', len(clusters))\n",
    "    print('Max number of tweets in labeled clusters:', max(lens))\n",
    "    print('Min number of tweets in labeled clusters:', min(lens))\n",
    "    print('Mean number of tweets in labeled clusters:', mean(lens))\n",
    "    print('Median number of tweets in labeled clusters:', median_low(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbac5d84-85f5-4d25-a16d-7a9dd636af66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 257\n",
      "Max number of tweets in labeled clusters: 18020\n",
      "Min number of tweets in labeled clusters: 2\n",
      "Mean number of tweets in labeled clusters: 372.74708171206225\n",
      "Median number of tweets in labeled clusters: 76\n"
     ]
    }
   ],
   "source": [
    "print_cluster_stats(TRUTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99098701-1e48-4de1-9503-7b578bb80473",
   "metadata": {},
   "source": [
    "## Tokenization & Vectorization\n",
    "\n",
    "*NOTE: It might be useful to convert tokens to incremental ids to speed up hash computations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64233d86-0760-4bc2-9558-d70d87fade96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer(\n",
    "    keep=['word'],\n",
    "    lower=True,\n",
    "    unidecode=True,\n",
    "    split_hashtags=True,\n",
    "    stoplist=STOP_WORDS_FR + [t + \"'\" for t in STOP_WORDS_FR],\n",
    "    reduce_words=True,\n",
    "    decode_html_entities=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22c23b5b-ae46-42b2-8442-2093e966575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@CCastaner, d√©l√©gu√© g√©n√©ral de #LaREM @enmarchefr confirme la convocation de Vincent Crase en vue de son licenciement  #AffaireBenalla #ComLoisS√©nat https://t.co/AX7ygSj6yt  \n",
      "[('word', 'delegue'), ('word', 'general'), ('word', 'rem'), ('word', 'confirme'), ('word', 'convocation'), ('word', 'vincent'), ('word', 'crase'), ('word', 'vue'), ('word', 'licenciement'), ('word', 'affaire'), ('word', 'benalla'), ('word', 'com'), ('word', 'lois'), ('word', 'senat')]\n",
      "\n",
      "Selon la presse Italienne, Monchi envisagerait une nouvelle offre pour Ziyech apr√®s avoir manqu√© de signer Malcolm √† la Roma.  Son co√©quipier David Neres est aussi une option. https://t.co/GEWnliv9Hq  \n",
      "[('word', 'selon'), ('word', 'presse'), ('word', 'italienne'), ('word', 'monchi'), ('word', 'envisagerait'), ('word', 'nouvelle'), ('word', 'offre'), ('word', 'ziyech'), ('word', 'manque'), ('word', 'signer'), ('word', 'malcolm'), ('word', 'roma'), ('word', 'coequipier'), ('word', 'david'), ('word', 'neres'), ('word', 'option')]\n",
      "\n",
      "@gchampeau @VentDeLiberteFR Collomb revient lourdement sur la loi \"fakenews\" qui pourrait censurer la libert√© d'expression car seuls le pouvoir et leurs complices pourraient diffuser. Avec cette loi cette affaire ne serait jamais apparu !!!!  On rappellera qu'il y a une salle plus grande √† l'Assembl√©e mais que pour une raison incertaine il a √©t√© choisi d'auditionner le ministre de l'Int√©rieur dans cette petite salle du 2e sous-sol. #DirectAN https://t.co/VrHVbZTJzu\n",
      "[('word', 'collomb'), ('word', 'revient'), ('word', 'lourdement'), ('word', 'loi'), ('word', 'fakenews'), ('word', 'pourrait'), ('word', 'censurer'), ('word', 'liberte'), ('word', 'expression'), ('word', 'car'), ('word', 'seuls'), ('word', 'pouvoir'), ('word', 'complices'), ('word', 'pourraient'), ('word', 'diffuser'), ('word', 'loi'), ('word', 'affaire'), ('word', 'serait'), ('word', 'apparu'), ('word', 'rappellera'), ('word', 'salle'), ('word', 'grande'), ('word', 'assemblee'), ('word', 'raison'), ('word', 'incertaine'), ('word', 'choisi'), ('word', 'auditionner'), ('word', 'ministre'), ('word', 'interieur'), ('word', 'petite'), ('word', 'salle'), ('word', '2e'), ('word', 'sous-sol'), ('word', 'direct'), ('word', 'an')]\n",
      "\n",
      "Ils ont dit qu'Alhaji Alejo n'√©tait pas bon, Paul Biya est entr√© en tant  que pr√©sident jusqu'√† aujourd'hui, rien de nouveau n'est jamais arriv√©  au Cameroun depuis de nombreuses ann√©es maintenant, qu'est-ce que ce  vieil homme veut encore? Faire du Cameroun son atout personnel? \"Cameroun : Paul Biya candidat √† sa propre succession\"¬†: https://t.co/alPkJdKznM via @YouTube \n",
      "[('word', 'alhaji'), ('word', 'alejo'), ('word', 'paul'), ('word', 'biya'), ('word', 'tant'), ('word', 'president'), ('word', \"jusqu'\"), ('word', \"aujourd'hui\"), ('word', 'nouveau'), ('word', 'arrive'), ('word', 'cameroun'), ('word', 'nombreuses'), ('word', 'annees'), ('word', 'est-ce'), ('word', 'vieil'), ('word', 'homme'), ('word', 'cameroun'), ('word', 'atout'), ('word', 'personnel'), ('word', 'cameroun'), ('word', 'paul'), ('word', 'biya'), ('word', 'candidat'), ('word', 'propre'), ('word', 'succession')]\n",
      "\n",
      "Donald Trump menace l‚ÄôIran dans des tweets √©crits en capitales - 20 Minutes https://t.co/65SHkq38ON via @GoogleNews  \n",
      "[('word', 'donald'), ('word', 'trump'), ('word', 'menace'), ('word', 'iran'), ('word', 'tweets'), ('word', 'ecrits'), ('word', 'capitales'), ('word', 'minutes')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_to_tokenize = sample(TWEETS, 5)\n",
    "\n",
    "for tweet in sample_to_tokenize:\n",
    "    print(tweet['text+quote+reply'])\n",
    "    print(list(tokenizer(tweet['text+quote+reply'])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41cbcfd1-3dcf-4138-a07d-ba386395893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f0fe85a8c84bb79a1d738fcd70e345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DOCUMENT_FREQUENCIES = Counter()\n",
    "\n",
    "for tweet in tqdm(TWEETS):\n",
    "    tweet['tokens'] = [token for _, token in tokenizer(tweet['text+quote+reply'])]\n",
    "    for token in tweet['tokens']:\n",
    "        DOCUMENT_FREQUENCIES[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e87b55-0fe8-4050-a2c1-ea8708ba85cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 95669\n"
     ]
    }
   ],
   "source": [
    "print('Size of vocabulary:', len(DOCUMENT_FREQUENCIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c00369b8-515f-437c-9e53-cd64e97ebd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(DOCUMENT_FREQUENCIES)\n",
    "TOKEN_IDS = {}\n",
    "INVERSE_DOCUMENT_FREQUENCIES = {}\n",
    "\n",
    "for i, (token, df) in enumerate(DOCUMENT_FREQUENCIES.items()):\n",
    "    if df < 10:\n",
    "        continue\n",
    "    TOKEN_IDS[token] = i\n",
    "    INVERSE_DOCUMENT_FREQUENCIES[token] = 1 + math.log((N + 1) / (df + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbae9d4f-1b8e-4382-86fa-4b869e3958b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary after df trimming: 16964\n"
     ]
    }
   ],
   "source": [
    "print('Size of vocabulary after df trimming:', len(INVERSE_DOCUMENT_FREQUENCIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3bb566a-486f-46e8-843a-caf57ae39435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1b90d730df4d17ad3b0f8c00e67567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VECTORS: List[Dict[int, float]] = []\n",
    "\n",
    "for tweet in tqdm(TWEETS):\n",
    "    vector = {}\n",
    "    \n",
    "    # TF is 1 as dimensions will be idempotently overwritten\n",
    "    for token in tweet['tokens']:\n",
    "        idf = INVERSE_DOCUMENT_FREQUENCIES.get(token)\n",
    "        \n",
    "        if idf is None:\n",
    "            continue\n",
    "        \n",
    "        vector[TOKEN_IDS[token]] = INVERSE_DOCUMENT_FREQUENCIES[token]\n",
    "        \n",
    "    # TODO: I need to make fog's sparse_normalize mutating\n",
    "    vector = sparse_normalize(vector)\n",
    "    VECTORS.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52584103-a605-4688-98b6-af7e5641e4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1184: 0.3335342812733879,\n",
       " 1185: 0.2775326630992335,\n",
       " 435: 0.2810242512362344,\n",
       " 372: 0.3224049284090944,\n",
       " 614: 0.17995974114938085,\n",
       " 1186: 0.27722975371913994,\n",
       " 1187: 0.3035279309471994,\n",
       " 1188: 0.33605302375009405,\n",
       " 1189: 0.34237169840543674,\n",
       " 1190: 0.286712874775498,\n",
       " 1191: 0.26258979193295,\n",
       " 105: 0.21478407949913875}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VECTORS[254]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46e3cb8e-cac6-40b7-aa2e-4f7c5a23e9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984537990809904"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 if v else 0 for v in VECTORS) / len(VECTORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e003abe-493c-45d7-bed4-3b8ddb550dc1",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7450cda3-57bd-4e82-ae22-d386ce1df103",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "from datetime import timedelta\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def sparse_dot_product(A: dict, B: dict):\n",
    "    \n",
    "    # Swapping so we iterate over the smallest set\n",
    "    if len(A) > len(B):\n",
    "        A, B = B, A\n",
    "\n",
    "    cdef float product  = 0.0\n",
    "\n",
    "    for k, w1 in A.items():\n",
    "        w2 = B.get(k)\n",
    "\n",
    "        if w2 is not None:\n",
    "            product += w1 * w2\n",
    "\n",
    "    return product\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def clustering(vectors: list, tweets: list):\n",
    "    cdef float best_metric\n",
    "    cdef int best_candidate\n",
    "    cdef float d\n",
    "    \n",
    "    cdef float one_day = timedelta(days=1).total_seconds()\n",
    "    cdef float date_bound\n",
    "    \n",
    "    for i, A in enumerate(vectors):\n",
    "        if not A:\n",
    "            continue\n",
    "        \n",
    "        tweet_a = tweets[i]\n",
    "\n",
    "        date_bound = tweet_a['timestamp'] + one_day\n",
    "        best_metric = -1.0\n",
    "        best_candidate = -1\n",
    "        d = 0.0\n",
    "\n",
    "        for j in range(i + 1, len(vectors)):\n",
    "            tweet_b = tweets[j]\n",
    "\n",
    "            if tweet_b['timestamp'] > date_bound:\n",
    "                break\n",
    "\n",
    "            B = vectors[j]\n",
    "            \n",
    "            if not B:\n",
    "                continue\n",
    "\n",
    "            d = sparse_dot_product(A, B)\n",
    "\n",
    "            if d == 0.0:\n",
    "                continue\n",
    "\n",
    "            if best_candidate < 0 or d > best_metric:\n",
    "                best_metric = d\n",
    "                best_candidate = j\n",
    "        \n",
    "        if best_candidate != -1:\n",
    "            yield (i, best_candidate, best_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "239f848a-fd52-485e-bb22-becfe33b1e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2fbc05b5654c96ab0308119a5778b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137757 [00:00<?, ?tweet/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EDGES = []\n",
    "\n",
    "for edge in tqdm(clustering(VECTORS, TWEETS), unit='tweet', total=len(VECTORS)):\n",
    "    EDGES.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c19bc2e4-a349-4f9e-8dde-fe09a634e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar tweets (similarity: 0.626914):\n",
      "\n",
      "1023125802140033025 - @Julien_FEBREAU @OconEsteban Mais il me semblait avoir lu que c'est de riche papa de stroll qui avait rachet√© force india ü§î  L'√©curie Force India plac√©e ce soir sous administration judiciaire par la justice britannique... Esp√©rons que cette √©curie compos√©e de gens brillants soient rapidement reprise et que @OconEsteban ''s‚Äô√©clipse'' pour aller briller vers d'autres cieux !\n",
      "---\n",
      "1023139157160460288 - @Julien_FEBREAU @OconEsteban Mais de quoi parlez vous tous ? Pauvre Sahara Force India ???..mouahahah...pour rappel le propri√©taire est un escroc notoire interdit de sortie du territoire britannique et condamn√© dans son propre pays !!  L'√©curie Force India plac√©e ce soir sous administration judiciaire par la justice britannique... Esp√©rons que cette √©curie compos√©e de gens brillants soient rapidement reprise et que @OconEsteban ''s‚Äô√©clipse'' pour aller briller vers d'autres cieux !\n"
     ]
    }
   ],
   "source": [
    "similar_pair = choice(EDGES)\n",
    "first_tweet = TWEETS[similar_pair[0]]\n",
    "second_tweet = TWEETS[similar_pair[1]]\n",
    "print('Similar tweets (similarity: %f):\\n' % similar_pair[2])\n",
    "print(first_tweet['id'], '-', first_tweet['text+quote+reply'])\n",
    "print('---')\n",
    "print(second_tweet['id'], '-', second_tweet['text+quote+reply'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54b553fe-1ac4-4320-a6e5-6f08da779882",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH = nx.Graph()\n",
    "\n",
    "for i, j, sim in EDGES:\n",
    "    i_id = TWEETS[i]['id']\n",
    "    j_id = TWEETS[j]['id']\n",
    "    \n",
    "    GRAPH.add_node(i_id)\n",
    "    GRAPH.add_node(j_id)\n",
    "    \n",
    "    if sim < 0.7:\n",
    "        continue\n",
    "        \n",
    "    GRAPH.add_edge(i_id, j_id)\n",
    "\n",
    "CLUSTERS = list(nx.connected_components(GRAPH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6cecd-f38e-476f-ab8b-05a064722c60",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f03141f-457b-4b8e-9b99-ee9523ee84f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 257\n",
      "Max number of tweets in labeled clusters: 18020\n",
      "Min number of tweets in labeled clusters: 2\n",
      "Mean number of tweets in labeled clusters: 372.74708171206225\n",
      "Median number of tweets in labeled clusters: 76\n"
     ]
    }
   ],
   "source": [
    "print_cluster_stats(TRUTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9953ef19-c921-4fac-9ae6-740cd2ddf7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 103577\n",
      "Max number of tweets in labeled clusters: 1026\n",
      "Min number of tweets in labeled clusters: 1\n",
      "Mean number of tweets in labeled clusters: 1.3276306515925351\n",
      "Median number of tweets in labeled clusters: 1\n"
     ]
    }
   ],
   "source": [
    "print_cluster_stats(CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "549cb7a6-86a4-4f1e-87e4-64ed15b07b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7525678886350682, 0.12087350641321211, 0.10680011944226461)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_matching(TRUTH, CLUSTERS, allow_additional_items=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
