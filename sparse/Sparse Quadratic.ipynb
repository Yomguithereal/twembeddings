{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26e001a-d9ad-4a85-80b9-03140f4cb361",
   "metadata": {},
   "source": [
    "# Sparse reproduction of clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a6196b-93ab-4ce7-b2c7-04f7bf073945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "from datetime import datetime, timedelta\n",
    "from random import sample, choice\n",
    "from statistics import mean, median_low\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from fog.tokenizers import WordTokenizer\n",
    "from fog.metrics import sparse_normalize, sparse_dot_product\n",
    "from fog.evaluation import best_matching\n",
    "from twitwi.constants import TWEET_DATETIME_FORMAT\n",
    "from stop_words import STOP_WORDS_FR\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b489f2-a483-4f77-8229-acb2c655707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e001aa35-3247-4bfa-82d5-1e8b4c990453",
   "metadata": {},
   "source": [
    "## Constants and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59114cb3-07ff-48b8-a4c0-7dfb149bb82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_DAY = timedelta(days=1)\n",
    "\n",
    "def parse_date(created_at):\n",
    "    return datetime.strptime(created_at, TWEET_DATETIME_FORMAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f7ace-67f1-4afb-b02a-e4efc518be28",
   "metadata": {},
   "source": [
    "## Reading tweets file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f768c4a4-8606-4b78-bf93-e0188735408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/event2018.tsv') as f:\n",
    "    ALL_TWEETS = list(csv.DictReader(f, delimiter='\\t'))\n",
    "    \n",
    "# Keeping tweets only once (to avoid fuzzy clusters present in the data)\n",
    "already_seen = set()\n",
    "TWEETS = []\n",
    "\n",
    "for tweet in ALL_TWEETS:\n",
    "    if tweet['id'] in already_seen:\n",
    "        continue\n",
    "    \n",
    "    already_seen.add(tweet['id'])\n",
    "    TWEETS.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263b7713-87a3-466a-9688-fa23ed49e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dates & parsing stuff\n",
    "for tweet in TWEETS:\n",
    "    tweet['event'] = int(tweet['event'])\n",
    "    tweet['date'] = parse_date(tweet['created_at'])\n",
    "    tweet['timestamp'] = tweet['date'].timestamp()\n",
    "    tweet['label'] = int(tweet['label'].split('.')[0]) if tweet['label'] else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984618b6-5c24-477a-9ed3-7a7aeed713a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making suuuuuuuure the tweets are sorted by date\n",
    "TWEETS = sorted(TWEETS, key=itemgetter('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce41a24-5cbf-4833-91ca-c2ff9b994463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 1018722125941755905\n",
      "label_day 0.0\n",
      "event 20180716001\n",
      "text #Rennes - La sortie de prison de Djamel Beghal [Vidéo exclusive] via @letelegramme https://t.co/tbOthY1Ren\n",
      "text+quote+reply #Rennes - La sortie de prison de Djamel Beghal [Vidéo exclusive] via @letelegramme https://t.co/tbOthY1Ren  \n",
      "image \n",
      "url_image \n",
      "user1 True\n",
      "user2 True\n",
      "user3 True\n",
      "created_at Mon Jul 16 05:00:56 +0000 2018\n",
      "label 0\n",
      "date 2018-07-16 05:00:56\n",
      "timestamp 1531710056.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in TWEETS[0].items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cfeef6e-7d15-41b6-ac37-53dafdf13ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 137757\n",
      "Total number of events: 327\n",
      "Total number of labels: 257\n",
      "Total number of tweets not labeled 41961\n"
     ]
    }
   ],
   "source": [
    "print('Total number of tweets:', len(TWEETS))\n",
    "print('Total number of events:', len(set(t['event'] for t in TWEETS)))\n",
    "print('Total number of labels:', len(set(t['label'] for t in TWEETS if t['label'] is not None)))\n",
    "print('Total number of tweets not labeled', sum(1 if t['label'] is None else 0 for t in TWEETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357cfbfa-1562-46e8-ac54-5f659a88ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUTH = defaultdict(list)\n",
    "\n",
    "for tweet in TWEETS:\n",
    "    if tweet['label'] is None:\n",
    "        continue\n",
    "        \n",
    "    TRUTH[tweet['label']].append(tweet['id'])\n",
    "\n",
    "TRUTH = list(TRUTH.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc9ae949-8030-4c2d-b5b0-63db36f45205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_stats(clusters):\n",
    "    lens = [len(cluster) for cluster in clusters]\n",
    "    \n",
    "    print('Number of clusters:', len(clusters))\n",
    "    print('Max number of tweets in clusters:', max(lens))\n",
    "    print('Min number of tweets in clusters:', min(lens))\n",
    "    print('Mean number of tweets in clusters:', mean(lens))\n",
    "    print('Median number of tweets in clusters:', median_low(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dbac5d84-85f5-4d25-a16d-7a9dd636af66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 257\n",
      "Max number of tweets in clusters: 18020\n",
      "Min number of tweets in clusters: 2\n",
      "Mean number of tweets in clusters: 372.74708171206225\n",
      "Median number of tweets in clusters: 76\n"
     ]
    }
   ],
   "source": [
    "print_cluster_stats(TRUTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99098701-1e48-4de1-9503-7b578bb80473",
   "metadata": {},
   "source": [
    "## Tokenization & Vectorization\n",
    "\n",
    "*NOTE: It might be useful to convert tokens to incremental ids to speed up hash computations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64233d86-0760-4bc2-9558-d70d87fade96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer(\n",
    "    keep=['word'],\n",
    "    lower=True,\n",
    "    unidecode=True,\n",
    "    split_hashtags=True,\n",
    "    stoplist=STOP_WORDS_FR + [t + \"'\" for t in STOP_WORDS_FR],\n",
    "    reduce_words=True,\n",
    "    decode_html_entities=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22c23b5b-ae46-42b2-8442-2093e966575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#PoseTonGaulois #MandelaDay #Mandela100 #AIF2018 #lesnapoleons Quels emoji etes-vous? https://t.co/8WFV7WWCyj\n",
      "[('word', 'pose'), ('word', 'gaulois'), ('word', 'mandela'), ('word', 'day'), ('word', 'mandela'), ('word', 'aif'), ('word', 'lesnapoleons'), ('word', 'quels'), ('word', 'emoji')]\n",
      "\n",
      "A la base @enmarchefr c'était une image d'illustration ! On pensait pas que vous en aviez dans vos placards... #LREM #perquisition #Benalla https://t.co/jYS7jTMfh5\n",
      "[('word', 'base'), ('word', 'image'), ('word', 'illustration'), ('word', 'pensait'), ('word', 'aviez'), ('word', 'placards'), ('word', 'lrem'), ('word', 'perquisition'), ('word', 'benalla')]\n",
      "\n",
      "En Macronie, c’est TF1 qui interroge les mis-en-examen, pas la commission d’enquête parlementaire #NouveauMonde #RepubliqueIrreprochable #BenallaTF1\n",
      "[('word', 'macronie'), ('word', 'tf1'), ('word', 'interroge'), ('word', 'mis-en-examen'), ('word', 'commission'), ('word', 'enquete'), ('word', 'parlementaire'), ('word', 'nouveau'), ('word', 'republique'), ('word', 'irreprochable'), ('word', 'benalla'), ('word', 'tf')]\n",
      "\n",
      "@GG_RMC @claireopetit @numero23tv Encore une payer à rien foutre comme Marlène schiappa\n",
      "[('word', 'payer'), ('word', 'foutre'), ('word', 'marlene'), ('word', 'schiappa')]\n",
      "\n",
      "@jmaphatie @RNational_off @FranceInsoumise @Deputee_Obono @Ugobernalicis @MLP_officiel Plus de barrière à votre malhonnêteté intellectuelle, Mr #apathie ? Il y a aussi le PS, le PC et LR sur cette vidéo. Par ailleurs le Modem le suit. Pardon, je m'attendais à ce que vous fassiez votre travail. Je ne sais pas ce qui m'a pris.\n",
      "[('word', 'barriere'), ('word', 'malhonnetete'), ('word', 'intellectuelle'), ('word', 'mr'), ('word', 'apathie'), ('word', 'ps'), ('word', 'pc'), ('word', 'lr'), ('word', 'video'), ('word', 'ailleurs'), ('word', 'modem'), ('word', 'suit'), ('word', 'pardon'), ('word', 'attendais'), ('word', 'fassiez'), ('word', 'travail')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_to_tokenize = sample(TWEETS, 5)\n",
    "\n",
    "for tweet in sample_to_tokenize:\n",
    "    print(tweet['text'])\n",
    "    print(list(tokenizer(tweet['text'])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41cbcfd1-3dcf-4138-a07d-ba386395893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ea8d27badd475d8cad8a2c9c910129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DOCUMENT_FREQUENCIES = Counter()\n",
    "\n",
    "for tweet in tqdm(TWEETS):\n",
    "    tweet['tokens'] = set(token for _, token in tokenizer(tweet['text']))\n",
    "    for token in tweet['tokens']:\n",
    "        DOCUMENT_FREQUENCIES[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e87b55-0fe8-4050-a2c1-ea8708ba85cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 84347\n"
     ]
    }
   ],
   "source": [
    "print('Size of vocabulary:', len(DOCUMENT_FREQUENCIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c00369b8-515f-437c-9e53-cd64e97ebd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(DOCUMENT_FREQUENCIES)\n",
    "TOKEN_IDS = {}\n",
    "INVERSE_DOCUMENT_FREQUENCIES = {}\n",
    "\n",
    "for i, (token, df) in enumerate(DOCUMENT_FREQUENCIES.items()):\n",
    "    if df < 10:\n",
    "        continue\n",
    "    TOKEN_IDS[token] = i\n",
    "    INVERSE_DOCUMENT_FREQUENCIES[token] = 1 + math.log((N + 1) / (df + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbae9d4f-1b8e-4382-86fa-4b869e3958b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary after df trimming: 14225\n"
     ]
    }
   ],
   "source": [
    "print('Size of vocabulary after df trimming:', len(INVERSE_DOCUMENT_FREQUENCIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3bb566a-486f-46e8-843a-caf57ae39435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfcfaf4e49c4b46a6f21ca0f74a6b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VECTORS: List[Dict[int, float]] = []\n",
    "\n",
    "for tweet in tqdm(TWEETS):\n",
    "    vector = {}\n",
    "\n",
    "    for token in tweet['tokens']:\n",
    "        idf = INVERSE_DOCUMENT_FREQUENCIES.get(token)\n",
    "        \n",
    "        if idf is None:\n",
    "            continue\n",
    "        \n",
    "        vector[TOKEN_IDS[token]] = INVERSE_DOCUMENT_FREQUENCIES[token]\n",
    "        \n",
    "    # TODO: I need to make fog's sparse_normalize mutating\n",
    "    vector = sparse_normalize(vector)\n",
    "    VECTORS.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52584103-a605-4688-98b6-af7e5641e4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1054: 0.2812133486304016,\n",
       " 1055: 0.2622558529793368,\n",
       " 1056: 0.27693067050703873,\n",
       " 551: 0.1854091644119339,\n",
       " 316: 0.3128608742351213,\n",
       " 1057: 0.35250162021837594,\n",
       " 1058: 0.3034911311178596,\n",
       " 1059: 0.3453139470633889,\n",
       " 606: 0.21657608745522078,\n",
       " 1060: 0.32932927293005787,\n",
       " 382: 0.2756006098998605,\n",
       " 1061: 0.2761651501983566}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VECTORS[254]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46e3cb8e-cac6-40b7-aa2e-4f7c5a23e9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997118113780062"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 if v else 0 for v in VECTORS) / len(VECTORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e003abe-493c-45d7-bed4-3b8ddb550dc1",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7450cda3-57bd-4e82-ae22-d386ce1df103",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "from datetime import timedelta\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def sparse_dot_product(A: dict, B: dict):\n",
    "    \n",
    "    # Swapping so we iterate over the smallest set\n",
    "    if len(A) > len(B):\n",
    "        A, B = B, A\n",
    "\n",
    "    cdef float product  = 0.0\n",
    "\n",
    "    for k, w1 in A.items():\n",
    "        w2 = B.get(k)\n",
    "\n",
    "        if w2 is not None:\n",
    "            product += w1 * w2\n",
    "\n",
    "    return product\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def clustering(vectors: list, tweets: list):\n",
    "    cdef float best_metric\n",
    "    cdef int best_candidate\n",
    "    cdef float d\n",
    "    \n",
    "    cdef float one_day = timedelta(days=1).total_seconds()\n",
    "    cdef float date_bound\n",
    "    \n",
    "    for i, A in enumerate(vectors):\n",
    "        if not A:\n",
    "            continue\n",
    "        \n",
    "        tweet_a = tweets[i]\n",
    "\n",
    "        date_bound = tweet_a['timestamp'] + one_day\n",
    "        best_metric = -1.0\n",
    "        best_candidate = -1\n",
    "        d = 0.0\n",
    "\n",
    "        for j in range(i + 1, len(vectors)):\n",
    "            tweet_b = tweets[j]\n",
    "\n",
    "            if tweet_b['timestamp'] > date_bound:\n",
    "                break\n",
    "\n",
    "            B = vectors[j]\n",
    "            \n",
    "            if not B:\n",
    "                continue\n",
    "\n",
    "            d = sparse_dot_product(A, B)\n",
    "\n",
    "            if d == 0.0:\n",
    "                continue\n",
    "\n",
    "            if best_candidate < 0 or d > best_metric:\n",
    "                best_metric = d\n",
    "                best_candidate = j\n",
    "        \n",
    "        if best_candidate != -1:\n",
    "            yield (i, best_candidate, best_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "239f848a-fd52-485e-bb22-becfe33b1e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed46db70d7374cceb0535f6606c1bae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137757 [00:00<?, ?tweet/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EDGES = []\n",
    "\n",
    "for edge in tqdm(clustering(VECTORS, TWEETS), unit='tweet', total=len(VECTORS)):\n",
    "    EDGES.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c19bc2e4-a349-4f9e-8dde-fe09a634e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar tweets (similarity: 0.276995):\n",
      "\n",
      "1024183150640095234 - nouveau débat sur qui aurait dû déclencher la procédure de l'article 40 du code de procédure pénale. nouveau renvoi de patate chaude. \"Je pensais que (Crase) était réserviste et que je ne pouvais rien faire\", répond Castaner #DirectSénat\n",
      "---\n",
      "1024228349038735360 - #Affaire #Benalla - #Sénat : procédure de licenciement contre Vincent Crase (Castaner) https://t.co/g3rQ9jQTJb https://t.co/mPDDg1dZx4\n"
     ]
    }
   ],
   "source": [
    "similar_pair = choice(EDGES)\n",
    "first_tweet = TWEETS[similar_pair[0]]\n",
    "second_tweet = TWEETS[similar_pair[1]]\n",
    "print('Similar tweets (similarity: %f):\\n' % similar_pair[2])\n",
    "print(first_tweet['id'], '-', first_tweet['text'])\n",
    "print('---')\n",
    "print(second_tweet['id'], '-', second_tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54b553fe-1ac4-4320-a6e5-6f08da779882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def components(t):\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    for i, j, sim in EDGES:\n",
    "        i_id = TWEETS[i]['id']\n",
    "        j_id = TWEETS[j]['id']\n",
    "\n",
    "        graph.add_node(i_id)\n",
    "        graph.add_node(j_id)\n",
    "\n",
    "        if sim < t:\n",
    "            continue\n",
    "\n",
    "        graph.add_edge(i_id, j_id)\n",
    "\n",
    "    return list(nx.connected_components(graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6cecd-f38e-476f-ab8b-05a064722c60",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f03141f-457b-4b8e-9b99-ee9523ee84f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 257\n",
      "Max number of tweets in clusters: 18020\n",
      "Min number of tweets in clusters: 2\n",
      "Mean number of tweets in clusters: 372.74708171206225\n",
      "Median number of tweets in clusters: 76\n"
     ]
    }
   ],
   "source": [
    "print_cluster_stats(TRUTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9953ef19-c921-4fac-9ae6-740cd2ddf7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0.01\n",
      "Number of clusters: 84\n",
      "Max number of tweets in clusters: 64115\n",
      "Min number of tweets in clusters: 2\n",
      "Mean number of tweets in clusters: 1634.5119047619048\n",
      "Median number of tweets in clusters: 4\n",
      "(0.762311100014652, 0.11992355764119321, 0.1014885283586643)\n",
      "\n",
      "t = 0.05\n",
      "Number of clusters: 88\n",
      "Max number of tweets in clusters: 57662\n",
      "Min number of tweets in clusters: 1\n",
      "Mean number of tweets in clusters: 1560.215909090909\n",
      "Median number of tweets in clusters: 4\n",
      "(0.7566657094350651, 0.12559201445436768, 0.10397436361024162)\n",
      "\n",
      "t = 0.1\n",
      "Number of clusters: 106\n",
      "Max number of tweets in clusters: 56768\n",
      "Min number of tweets in clusters: 1\n",
      "Mean number of tweets in clusters: 1295.2735849056603\n",
      "Median number of tweets in clusters: 4\n",
      "(0.766611498531239, 0.13252802343820866, 0.11441593269650639)\n",
      "\n",
      "t = 0.15\n",
      "Number of clusters: 702\n",
      "Max number of tweets in clusters: 43306\n",
      "Min number of tweets in clusters: 1\n",
      "Mean number of tweets in clusters: 195.58262108262107\n",
      "Median number of tweets in clusters: 1\n",
      "(0.8997583583241402, 0.11145216664939107, 0.10766796435559368)\n",
      "\n",
      "t = 0.2\n",
      "Number of clusters: 5275\n",
      "Max number of tweets in clusters: 33287\n",
      "Min number of tweets in clusters: 1\n",
      "Mean number of tweets in clusters: 26.02824644549763\n",
      "Median number of tweets in clusters: 1\n",
      "(0.9625739455534662, 0.039818393457672824, 0.04386242411519665)\n",
      "\n",
      "t = 0.7\n",
      "Number of clusters: 105105\n",
      "Max number of tweets in clusters: 1026\n",
      "Min number of tweets in clusters: 1\n",
      "Mean number of tweets in clusters: 1.3063032205889349\n",
      "Median number of tweets in clusters: 1\n",
      "(0.9995195290575148, 0.003594946236653718, 0.0061803344953214705)\n",
      "\n",
      "t = 0.8\n",
      "Number of clusters: 112506\n",
      "Max number of tweets in clusters: 1026\n",
      "Min number of tweets in clusters: 1\n",
      "Mean number of tweets in clusters: 1.2203704691305353\n",
      "Median number of tweets in clusters: 1\n",
      "(0.9997764529014529, 0.0033226831293483704, 0.005849916085987721)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in (0.01, 0.05, 0.1, 0.15, 0.2, 0.7, 0.8):\n",
    "    print('t =', t)\n",
    "    clusters = components(t)\n",
    "    print_cluster_stats(clusters)\n",
    "    print(best_matching(TRUTH, clusters, allow_additional_items=True))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
