{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26e001a-d9ad-4a85-80b9-03140f4cb361",
   "metadata": {},
   "source": [
    "# Sparse reproduction of clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a6196b-93ab-4ce7-b2c7-04f7bf073945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "from datetime import datetime, timedelta\n",
    "from random import sample, choice\n",
    "from statistics import mean, median_low\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from fog.tokenizers import WordTokenizer\n",
    "from fog.metrics import sparse_normalize, sparse_dot_product\n",
    "from fog.evaluation import best_matching\n",
    "from twitwi.constants import TWEET_DATETIME_FORMAT\n",
    "from stop_words import STOP_WORDS_FR\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b489f2-a483-4f77-8229-acb2c655707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e001aa35-3247-4bfa-82d5-1e8b4c990453",
   "metadata": {},
   "source": [
    "## Constants and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59114cb3-07ff-48b8-a4c0-7dfb149bb82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_DAY = timedelta(days=1)\n",
    "\n",
    "def parse_date(created_at):\n",
    "    return datetime.strptime(created_at, TWEET_DATETIME_FORMAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f7ace-67f1-4afb-b02a-e4efc518be28",
   "metadata": {},
   "source": [
    "## Reading tweets file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f768c4a4-8606-4b78-bf93-e0188735408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/event2018.tsv') as f:\n",
    "    ALL_TWEETS = list(csv.DictReader(f, delimiter='\\t'))\n",
    "    \n",
    "# Keeping tweets only once (to avoid fuzzy clusters present in the data)\n",
    "already_seen = set()\n",
    "TWEETS = []\n",
    "\n",
    "for tweet in ALL_TWEETS:\n",
    "    if tweet['id'] in already_seen:\n",
    "        continue\n",
    "    \n",
    "    already_seen.add(tweet['id'])\n",
    "    TWEETS.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263b7713-87a3-466a-9688-fa23ed49e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dates & parsing stuff\n",
    "for tweet in TWEETS:\n",
    "    tweet['event'] = int(tweet['event'])\n",
    "    tweet['date'] = parse_date(tweet['created_at'])\n",
    "    tweet['timestamp'] = tweet['date'].timestamp()\n",
    "    tweet['label'] = int(tweet['label'].split('.')[0]) if tweet['label'] else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984618b6-5c24-477a-9ed3-7a7aeed713a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making suuuuuuuure the tweets are sorted by date\n",
    "TWEETS = sorted(TWEETS, key=itemgetter('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce41a24-5cbf-4833-91ca-c2ff9b994463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 1018722125941755905\n",
      "label_day 0.0\n",
      "event 20180716001\n",
      "text #Rennes - La sortie de prison de Djamel Beghal [Vidéo exclusive] via @letelegramme https://t.co/tbOthY1Ren\n",
      "text+quote+reply #Rennes - La sortie de prison de Djamel Beghal [Vidéo exclusive] via @letelegramme https://t.co/tbOthY1Ren  \n",
      "image \n",
      "url_image \n",
      "user1 True\n",
      "user2 True\n",
      "user3 True\n",
      "created_at Mon Jul 16 05:00:56 +0000 2018\n",
      "label 0\n",
      "date 2018-07-16 05:00:56\n",
      "timestamp 1531710056.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in TWEETS[0].items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cfeef6e-7d15-41b6-ac37-53dafdf13ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 137757\n",
      "Total number of events: 327\n",
      "Total number of labels: 257\n",
      "Total number of tweets not labeled 41961\n"
     ]
    }
   ],
   "source": [
    "print('Total number of tweets:', len(TWEETS))\n",
    "print('Total number of events:', len(set(t['event'] for t in TWEETS)))\n",
    "print('Total number of labels:', len(set(t['label'] for t in TWEETS if t['label'] is not None)))\n",
    "print('Total number of tweets not labeled', sum(1 if t['label'] is None else 0 for t in TWEETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357cfbfa-1562-46e8-ac54-5f659a88ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUTH = defaultdict(list)\n",
    "\n",
    "for tweet in TWEETS:\n",
    "    if tweet['label'] is None:\n",
    "        continue\n",
    "        \n",
    "    TRUTH[tweet['label']].append(tweet['id'])\n",
    "\n",
    "TRUTH = list(TRUTH.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9ae949-8030-4c2d-b5b0-63db36f45205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_stats(clusters):\n",
    "    lens = [len(cluster) for cluster in clusters]\n",
    "    \n",
    "    print('Number of clusters:', len(clusters))\n",
    "    print('Max number of tweets in labeled clusters:', max(lens))\n",
    "    print('Min number of tweets in labeled clusters:', min(lens))\n",
    "    print('Mean number of tweets in labeled clusters:', mean(lens))\n",
    "    print('Median number of tweets in labeled clusters:', median_low(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbac5d84-85f5-4d25-a16d-7a9dd636af66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 257\n",
      "Max number of tweets in labeled clusters: 18020\n",
      "Min number of tweets in labeled clusters: 2\n",
      "Mean number of tweets in labeled clusters: 372.74708171206225\n",
      "Median number of tweets in labeled clusters: 76\n"
     ]
    }
   ],
   "source": [
    "print_cluster_stats(TRUTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99098701-1e48-4de1-9503-7b578bb80473",
   "metadata": {},
   "source": [
    "## Tokenization & Vectorization\n",
    "\n",
    "*NOTE: It might be useful to convert tokens to incremental ids to speed up hash computations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64233d86-0760-4bc2-9558-d70d87fade96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer(\n",
    "    keep=['word'],\n",
    "    lower=True,\n",
    "    unidecode=True,\n",
    "    split_hashtags=True,\n",
    "    stoplist=STOP_WORDS_FR + [t + \"'\" for t in STOP_WORDS_FR],\n",
    "    reduce_words=True,\n",
    "    decode_html_entities=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22c23b5b-ae46-42b2-8442-2093e966575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@CCastaner, délégué général de #LaREM @enmarchefr confirme la convocation de Vincent Crase en vue de son licenciement  #AffaireBenalla #ComLoisSénat https://t.co/AX7ygSj6yt  \n",
      "[('word', 'delegue'), ('word', 'general'), ('word', 'rem'), ('word', 'confirme'), ('word', 'convocation'), ('word', 'vincent'), ('word', 'crase'), ('word', 'vue'), ('word', 'licenciement'), ('word', 'affaire'), ('word', 'benalla'), ('word', 'com'), ('word', 'lois'), ('word', 'senat')]\n",
      "\n",
      "Selon la presse Italienne, Monchi envisagerait une nouvelle offre pour Ziyech après avoir manqué de signer Malcolm à la Roma.  Son coéquipier David Neres est aussi une option. https://t.co/GEWnliv9Hq  \n",
      "[('word', 'selon'), ('word', 'presse'), ('word', 'italienne'), ('word', 'monchi'), ('word', 'envisagerait'), ('word', 'nouvelle'), ('word', 'offre'), ('word', 'ziyech'), ('word', 'manque'), ('word', 'signer'), ('word', 'malcolm'), ('word', 'roma'), ('word', 'coequipier'), ('word', 'david'), ('word', 'neres'), ('word', 'option')]\n",
      "\n",
      "@gchampeau @VentDeLiberteFR Collomb revient lourdement sur la loi \"fakenews\" qui pourrait censurer la liberté d'expression car seuls le pouvoir et leurs complices pourraient diffuser. Avec cette loi cette affaire ne serait jamais apparu !!!!  On rappellera qu'il y a une salle plus grande à l'Assemblée mais que pour une raison incertaine il a été choisi d'auditionner le ministre de l'Intérieur dans cette petite salle du 2e sous-sol. #DirectAN https://t.co/VrHVbZTJzu\n",
      "[('word', 'collomb'), ('word', 'revient'), ('word', 'lourdement'), ('word', 'loi'), ('word', 'fakenews'), ('word', 'pourrait'), ('word', 'censurer'), ('word', 'liberte'), ('word', 'expression'), ('word', 'car'), ('word', 'seuls'), ('word', 'pouvoir'), ('word', 'complices'), ('word', 'pourraient'), ('word', 'diffuser'), ('word', 'loi'), ('word', 'affaire'), ('word', 'serait'), ('word', 'apparu'), ('word', 'rappellera'), ('word', 'salle'), ('word', 'grande'), ('word', 'assemblee'), ('word', 'raison'), ('word', 'incertaine'), ('word', 'choisi'), ('word', 'auditionner'), ('word', 'ministre'), ('word', 'interieur'), ('word', 'petite'), ('word', 'salle'), ('word', '2e'), ('word', 'sous-sol'), ('word', 'direct'), ('word', 'an')]\n",
      "\n",
      "Ils ont dit qu'Alhaji Alejo n'était pas bon, Paul Biya est entré en tant  que président jusqu'à aujourd'hui, rien de nouveau n'est jamais arrivé  au Cameroun depuis de nombreuses années maintenant, qu'est-ce que ce  vieil homme veut encore? Faire du Cameroun son atout personnel? \"Cameroun : Paul Biya candidat à sa propre succession\" : https://t.co/alPkJdKznM via @YouTube \n",
      "[('word', 'alhaji'), ('word', 'alejo'), ('word', 'paul'), ('word', 'biya'), ('word', 'tant'), ('word', 'president'), ('word', \"jusqu'\"), ('word', \"aujourd'hui\"), ('word', 'nouveau'), ('word', 'arrive'), ('word', 'cameroun'), ('word', 'nombreuses'), ('word', 'annees'), ('word', 'est-ce'), ('word', 'vieil'), ('word', 'homme'), ('word', 'cameroun'), ('word', 'atout'), ('word', 'personnel'), ('word', 'cameroun'), ('word', 'paul'), ('word', 'biya'), ('word', 'candidat'), ('word', 'propre'), ('word', 'succession')]\n",
      "\n",
      "Donald Trump menace l’Iran dans des tweets écrits en capitales - 20 Minutes https://t.co/65SHkq38ON via @GoogleNews  \n",
      "[('word', 'donald'), ('word', 'trump'), ('word', 'menace'), ('word', 'iran'), ('word', 'tweets'), ('word', 'ecrits'), ('word', 'capitales'), ('word', 'minutes')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_to_tokenize = sample(TWEETS, 5)\n",
    "\n",
    "for tweet in sample_to_tokenize:\n",
    "    print(tweet['text+quote+reply'])\n",
    "    print(list(tokenizer(tweet['text+quote+reply'])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41cbcfd1-3dcf-4138-a07d-ba386395893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f0fe85a8c84bb79a1d738fcd70e345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DOCUMENT_FREQUENCIES = Counter()\n",
    "\n",
    "for tweet in tqdm(TWEETS):\n",
    "    tweet['tokens'] = [token for _, token in tokenizer(tweet['text+quote+reply'])]\n",
    "    for token in tweet['tokens']:\n",
    "        DOCUMENT_FREQUENCIES[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e87b55-0fe8-4050-a2c1-ea8708ba85cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 95669\n"
     ]
    }
   ],
   "source": [
    "print('Size of vocabulary:', len(DOCUMENT_FREQUENCIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c00369b8-515f-437c-9e53-cd64e97ebd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(DOCUMENT_FREQUENCIES)\n",
    "TOKEN_IDS = {}\n",
    "INVERSE_DOCUMENT_FREQUENCIES = {}\n",
    "\n",
    "for i, (token, df) in enumerate(DOCUMENT_FREQUENCIES.items()):\n",
    "    if df < 10:\n",
    "        continue\n",
    "    TOKEN_IDS[token] = i\n",
    "    INVERSE_DOCUMENT_FREQUENCIES[token] = 1 + math.log((N + 1) / (df + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbae9d4f-1b8e-4382-86fa-4b869e3958b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary after df trimming: 16964\n"
     ]
    }
   ],
   "source": [
    "print('Size of vocabulary after df trimming:', len(INVERSE_DOCUMENT_FREQUENCIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3bb566a-486f-46e8-843a-caf57ae39435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1b90d730df4d17ad3b0f8c00e67567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VECTORS: List[Dict[int, float]] = []\n",
    "\n",
    "for tweet in tqdm(TWEETS):\n",
    "    vector = {}\n",
    "    \n",
    "    # TF is 1 as dimensions will be idempotently overwritten\n",
    "    for token in tweet['tokens']:\n",
    "        idf = INVERSE_DOCUMENT_FREQUENCIES.get(token)\n",
    "        \n",
    "        if idf is None:\n",
    "            continue\n",
    "        \n",
    "        vector[TOKEN_IDS[token]] = INVERSE_DOCUMENT_FREQUENCIES[token]\n",
    "        \n",
    "    # TODO: I need to make fog's sparse_normalize mutating\n",
    "    vector = sparse_normalize(vector)\n",
    "    VECTORS.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52584103-a605-4688-98b6-af7e5641e4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1184: 0.3335342812733879,\n",
       " 1185: 0.2775326630992335,\n",
       " 435: 0.2810242512362344,\n",
       " 372: 0.3224049284090944,\n",
       " 614: 0.17995974114938085,\n",
       " 1186: 0.27722975371913994,\n",
       " 1187: 0.3035279309471994,\n",
       " 1188: 0.33605302375009405,\n",
       " 1189: 0.34237169840543674,\n",
       " 1190: 0.286712874775498,\n",
       " 1191: 0.26258979193295,\n",
       " 105: 0.21478407949913875}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VECTORS[254]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46e3cb8e-cac6-40b7-aa2e-4f7c5a23e9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984537990809904"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 if v else 0 for v in VECTORS) / len(VECTORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e003abe-493c-45d7-bed4-3b8ddb550dc1",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7450cda3-57bd-4e82-ae22-d386ce1df103",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "from datetime import timedelta\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def sparse_dot_product(A: dict, B: dict):\n",
    "    \n",
    "    # Swapping so we iterate over the smallest set\n",
    "    if len(A) > len(B):\n",
    "        A, B = B, A\n",
    "\n",
    "    cdef float product  = 0.0\n",
    "\n",
    "    for k, w1 in A.items():\n",
    "        w2 = B.get(k)\n",
    "\n",
    "        if w2 is not None:\n",
    "            product += w1 * w2\n",
    "\n",
    "    return product\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def clustering(vectors: list, tweets: list):\n",
    "    cdef float best_metric\n",
    "    cdef int best_candidate\n",
    "    cdef float d\n",
    "    \n",
    "    cdef float one_day = timedelta(days=1).total_seconds()\n",
    "    cdef float date_bound\n",
    "    \n",
    "    for i, A in enumerate(vectors):\n",
    "        if not A:\n",
    "            continue\n",
    "        \n",
    "        tweet_a = tweets[i]\n",
    "\n",
    "        date_bound = tweet_a['timestamp'] + one_day\n",
    "        best_metric = -1.0\n",
    "        best_candidate = -1\n",
    "        d = 0.0\n",
    "\n",
    "        for j in range(i + 1, len(vectors)):\n",
    "            tweet_b = tweets[j]\n",
    "\n",
    "            if tweet_b['timestamp'] > date_bound:\n",
    "                break\n",
    "\n",
    "            B = vectors[j]\n",
    "            \n",
    "            if not B:\n",
    "                continue\n",
    "\n",
    "            d = sparse_dot_product(A, B)\n",
    "\n",
    "            if d == 0.0:\n",
    "                continue\n",
    "\n",
    "            if best_candidate < 0 or d > best_metric:\n",
    "                best_metric = d\n",
    "                best_candidate = j\n",
    "        \n",
    "        if best_candidate != -1:\n",
    "            yield (i, best_candidate, best_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "239f848a-fd52-485e-bb22-becfe33b1e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2fbc05b5654c96ab0308119a5778b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137757 [00:00<?, ?tweet/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EDGES = []\n",
    "\n",
    "for edge in tqdm(clustering(VECTORS, TWEETS), unit='tweet', total=len(VECTORS)):\n",
    "    EDGES.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c19bc2e4-a349-4f9e-8dde-fe09a634e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar tweets (similarity: 0.626914):\n",
      "\n",
      "1023125802140033025 - @Julien_FEBREAU @OconEsteban Mais il me semblait avoir lu que c'est de riche papa de stroll qui avait racheté force india 🤔  L'écurie Force India placée ce soir sous administration judiciaire par la justice britannique... Espérons que cette écurie composée de gens brillants soient rapidement reprise et que @OconEsteban ''s’éclipse'' pour aller briller vers d'autres cieux !\n",
      "---\n",
      "1023139157160460288 - @Julien_FEBREAU @OconEsteban Mais de quoi parlez vous tous ? Pauvre Sahara Force India ???..mouahahah...pour rappel le propriétaire est un escroc notoire interdit de sortie du territoire britannique et condamné dans son propre pays !!  L'écurie Force India placée ce soir sous administration judiciaire par la justice britannique... Espérons que cette écurie composée de gens brillants soient rapidement reprise et que @OconEsteban ''s’éclipse'' pour aller briller vers d'autres cieux !\n"
     ]
    }
   ],
   "source": [
    "similar_pair = choice(EDGES)\n",
    "first_tweet = TWEETS[similar_pair[0]]\n",
    "second_tweet = TWEETS[similar_pair[1]]\n",
    "print('Similar tweets (similarity: %f):\\n' % similar_pair[2])\n",
    "print(first_tweet['id'], '-', first_tweet['text+quote+reply'])\n",
    "print('---')\n",
    "print(second_tweet['id'], '-', second_tweet['text+quote+reply'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54b553fe-1ac4-4320-a6e5-6f08da779882",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH = nx.Graph()\n",
    "\n",
    "for i, j, sim in EDGES:\n",
    "    i_id = TWEETS[i]['id']\n",
    "    j_id = TWEETS[j]['id']\n",
    "    \n",
    "    GRAPH.add_node(i_id)\n",
    "    GRAPH.add_node(j_id)\n",
    "    \n",
    "    if sim < 0.7:\n",
    "        continue\n",
    "        \n",
    "    GRAPH.add_edge(i_id, j_id)\n",
    "\n",
    "CLUSTERS = list(nx.connected_components(GRAPH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6cecd-f38e-476f-ab8b-05a064722c60",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f03141f-457b-4b8e-9b99-ee9523ee84f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 257\n",
      "Max number of tweets in labeled clusters: 18020\n",
      "Min number of tweets in labeled clusters: 2\n",
      "Mean number of tweets in labeled clusters: 372.74708171206225\n",
      "Median number of tweets in labeled clusters: 76\n"
     ]
    }
   ],
   "source": [
    "print_cluster_stats(TRUTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9953ef19-c921-4fac-9ae6-740cd2ddf7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 103577\n",
      "Max number of tweets in labeled clusters: 1026\n",
      "Min number of tweets in labeled clusters: 1\n",
      "Mean number of tweets in labeled clusters: 1.3276306515925351\n",
      "Median number of tweets in labeled clusters: 1\n"
     ]
    }
   ],
   "source": [
    "print_cluster_stats(CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "549cb7a6-86a4-4f1e-87e4-64ed15b07b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7525678886350682, 0.12087350641321211, 0.10680011944226461)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_matching(TRUTH, CLUSTERS, allow_additional_items=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
